<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>kube-scheduler定制，支持深度学习批处理任务调度 - sealyun | kubernetes安装</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="fanux" /><meta name="description" content="kubernetes集群三步安装 什么是批处理任务 深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.54.0 with even 4.0.0" />


<link rel="canonical" href="https://sealyun.com/post/kube-batch/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="kube-scheduler定制，支持深度学习批处理任务调度" />
<meta property="og:description" content="kubernetes集群三步安装 什么是批处理任务 深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sealyun.com/post/kube-batch/" />
<meta property="article:published_time" content="2018-12-25T10:54:24&#43;02:00"/>
<meta property="article:modified_time" content="2018-12-25T10:54:24&#43;02:00"/>

<meta itemprop="name" content="kube-scheduler定制，支持深度学习批处理任务调度">
<meta itemprop="description" content="kubernetes集群三步安装 什么是批处理任务 深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务">


<meta itemprop="datePublished" content="2018-12-25T10:54:24&#43;02:00" />
<meta itemprop="dateModified" content="2018-12-25T10:54:24&#43;02:00" />
<meta itemprop="wordCount" content="3389">



<meta itemprop="keywords" content="event,dotScale,sketchnote," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="kube-scheduler定制，支持深度学习批处理任务调度"/>
<meta name="twitter:description" content="kubernetes集群三步安装 什么是批处理任务 深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SealYun</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="">
        <li class="mobile-menu-item">Istio下载</li>
      </a><a href="/pro/products">
        <li class="mobile-menu-item">Kubernetes下载</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SealYun</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="">Istio下载</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/pro/products">Kubernetes下载</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">kube-scheduler定制，支持深度学习批处理任务调度</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-12-25 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#什么是批处理任务">什么是批处理任务</a></li>
<li><a href="#实现难点">实现难点</a></li>
<li><a href="#实现">实现</a>
<ul>
<li><a href="#延迟绑定">延迟绑定</a></li>
<li><a href="#检查资源是否充足checkresourceisenough">检查资源是否充足CheckResourceIsEnough</a></li>
<li><a href="#如何获取节点已经分配gpu的数量">如何获取节点已经分配GPU的数量</a></li>
<li><a href="#增加podupdater-可更新podcondition状态">增加podupdater，可更新podcondition状态</a></li>
<li><a href="#需要把batch-scheduler的cache给generic-scheduler资源检查时需要用">需要把batch scheduler的cache给generic_scheduler资源检查时需要用</a></li>
<li><a href="#检查资源是否充足详细算法">检查资源是否充足详细算法：</a></li>
</ul></li>
<li><a href="#关于gpu的使用与发现">关于GPU的使用与发现</a></li>
<li><a href="#总结">总结</a></li>
<li><a href="#公众号">公众号：</a>
<ul>
<li>
<ul>
<li><a href="#微信群">微信群：</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<blockquote>
<p><a href="https://sealyun.com/pro/products/">kubernetes集群三步安装</a></p>
</blockquote>

<h1 id="什么是批处理任务">什么是批处理任务</h1>

<p>深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务。</p>

<p>这样就会有一个问题</p>

<p>一个任务要起100个pod，每个pod需要一张卡，总共需要100张GPU卡，而集群中只有99张空闲的GPU卡，这样默认的k8s调度器会如何处理？</p>

<p>因为默认调度器是一个一个pod调度的，只会检查单个pod资源够不够，这样前99个都能成功，最后一个pod调度失败。</p>

<p>这样非常有可能造成</p>

<ol>
<li>任务跑不了<br /></li>
<li>前99个占着GPU不释放，新的任务无法调度</li>
<li>严重时整个集群死锁，都“占着茅坑不拉屎”</li>
</ol>

<p>所以需要在调度时对整个task所需所有资源进行检查，当集群总体资源不够时，一个pod都得不到调度。</p>

<p>社区提供了一个能支持这种特性的<a href="https://github.com/kubernetes-sigs/kube-batch/blob/master/doc/usage/tutorial.md">调度器</a>
但是这个调度器是没办法和原生调度器很好的配合工作的</p>

<ol>
<li>最大的问题在于两个调度器都有cache，这样cache的内容会冲突，导致调度混乱</li>
<li>这个调度器没法和原生调度器同时起作用，这样用了这个batch调度器后就没法用亲和性什么的特性了</li>
</ol>

<p>所以我们做的事是将两者特性融合，选择的方法是定制化开发kube-scheduler</p>

<p>其实scheduler是可以通过extender扩展的，但是extender还是太弱了，它仅能在预选和优选过程中加入自己的过滤策略，而这对于批处理任务远远不够。</p>

<h1 id="实现难点">实现难点</h1>

<blockquote>
<p>需要优选时加batch任务检查
拿到一个pod &mdash;&gt; 如果是一个batchpod &mdash;&gt; 查询集群资源是否满足batch任务&mdash;&gt;否调度失败</p>

<p>需要保障batch任务中其它pod能得到调度</p>
</blockquote>

<p>如果集群资源能满足这个batch任务直接去bind有个问题：
假设调度队列是这样,假设集群中有三个GPU，而batch任务需要三个GPU：</p>

<table>
<thead>
<tr>
<th>A batch pod -&gt;</th>
<th>pod -&gt;</th>
<th>pod -&gt;</th>
<th>A batch pod -&gt;</th>
<th>A batch pod</th>
</tr>
</thead>

<tbody>
<tr>
<td>集群资源够 调度成功</td>
<td>调度了别的pod</td>
<td>调度了别的pod</td>
<td>GPU被别的pod占用 GPU不够 失败</td>
<td>GPU不够 失败</td>
</tr>
</tbody>
</table>

<p>所以最终结果是A批任务占用了一个GPU但是整个任务是调度失败的，那一个GPU还得不到释放</p>

<p>所以需要修改pod调度队列里的顺序?让A batch pod连续调度? 没这么简单，</p>

<p>pod调度是创建协程并发调度的，这样即便去调整任务队列里pod的顺序也不一定能保证batch任务其它pod能得到优先调度。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span></pre></td>
<td class="lntd">
<pre class="chroma">go wait.Until(sched.scheduleOne, 0, sched.config.StopEverything)</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>只要batch pod走到Bind逻辑了就没有回头路了</p>
</blockquote>

<p>batch任务中所有pod先进行assume调度，其中任意一个失败就清理掉其它已经bind但是还没实际进行调度的pod。 并把所有pod扔回队列，或者直接返回调度失败清理改任务的pod，让上层重新触发?</p>

<p>scheduler流程 scheduler/sheduler.go scheduleOne逻辑：</p>

<p>选节点-&gt;cache assume pod on node-&gt; 创建协程bind</p>

<p>所以在assume时去检查，不满足退还已经调度的pod是不可行的，因为之前batch任务中的pod可能已经bind过了， 所以只能batch任务中最后一个pod得到确认才能去bind前面的pod</p>

<blockquote>
<p>预占用策略
预占用策略： 第一个batch pod任务来时，检查集群资源是不是够，如果够进行预占，把其它几个node打上标记，让接下来pod无法占用其它的node，这样batch任务其实pod过来就有节点可用。</p>
</blockquote>

<p>回到了不能bind的问题。。。</p>

<p>这种问题有两点：</p>

<p>如何知道batch任务中其它pod需要什么样的节点，如果pod都一样问题可简化
如果后面的pod失败了，第一个pod还是已经bind，还是会出现一样的问题
最终还是在所有pod assume之前不能bind单个pod</p>

<p>综上，需要在几个地方处理</p>

<p>队列最好用优先级队列，把正在调度的pod的关联pod优先级提高
选节点时做判断，看集群资源是否够
选好节点assume pod时检查，如果自己不够或者pod组不够就不去bind
问题是之前的pod已经走了bind流程，所以最重要的是如何解决让之前的pod不去bind，延迟bind</p>

<blockquote>
<p>最终方案 - 延迟绑定</p>
</blockquote>

<p>方案：在batch任务bind时进行特殊处理</p>

<ol>
<li>如果是batch任务扔进task cache，不进行binding</li>
<li>如果batch任务最后一个pod扔进task cache,该task ready，放进bind队列</li>
<li>在bind队列里取task 进行bind，task互斥锁与普通pod bind时互斥</li>
</ol>

<blockquote>
<p>使用
batch任务使用，pod增加两个注解：</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></pre></td>
<td class="lntd">
<pre class="chroma">      annotations:
        scheduling.k8s.io/group-name: qj-1
        scheduling.k8s.io/group-pod-num: 3</pre></td></tr></table>
</div>
</div>
<p>pod加上这两个注解表示属于同一个task, num表示task里有多少pod。</p>

<p>本来是再定义一个CRD去描述这个task，耦合会小一些，但是实现麻烦些，需要多监听一个CRD，偷懒就没这样做</p>

<h1 id="实现">实现</h1>

<p>延迟绑定流程：
<img src="/batch-scheduler-flow.png" alt="" /></p>

<ul>
<li>如果是普通的pod，找到节点后assume就直接bind</li>
<li>如果是批处理任务，直接扔到批处理缓存中返回</li>
<li>有个协程一直检查批缓存中是否有成功的task (pod都齐了)</li>
<li>成功的task扔进binding队列，worker取成功的task进行批量绑定，绑定时与普通pod互斥</li>
</ul>

<p>batch scheduler接口与成员
<img src="/batch-scheduler.png" alt="" /></p>

<p>Run 起一个协程检查成功的task并塞入队列
RunBind 起一个task绑定协程
PodQuePriority 去动态修改pod队列的优先级，让同task的pod优先调度</p>

<p>执行流程：
<img src="/batch-scheduler-run.png" alt="" /></p>

<h2 id="延迟绑定">延迟绑定</h2>

<p>scheduler/scheduler.go:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//fanux if it is a batch pod, return
	if sched.Config.BatchScheduler.IsBatchPod(assumedPod) {
		err = sched.Config.BatchScheduler.HandleBatchPod(assumedPod)
		if err != nil {
			glog.Errorf(&#34;schedule batch pod failed: %v&#34;, assumedPod.Namespace, assumedPod.Name)
		}
		return
	}</pre></td></tr></table>
</div>
</div>
<p>增加绑定互斥，防止batch任务和普通pod同事binding:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></pre></td>
<td class="lntd">
<pre class="chroma">	go func() {
		//fanux add bind mutex
		sched.Config.BatchScheduler.Lock()
		defer sched.Config.BatchScheduler.UnLock()

		err := sched.bind(assumedPod, &amp;v1.Binding{</pre></td></tr></table>
</div>
</div>
<h2 id="检查资源是否充足checkresourceisenough">检查资源是否充足CheckResourceIsEnough</h2>

<p>should&rsquo;t use filterFunc, needs nodelist</p>

<p>scheduler/util/batch.go</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></pre></td>
<td class="lntd">
<pre class="chroma"><span class="kn">package</span> <span class="nx">util</span>

<span class="kn">import</span> <span class="s">&#34;api/core/v1&#34;</span>

<span class="c1">//CheckResourceIsEnough is
</span><span class="c1"></span><span class="kd">func</span> <span class="nf">CheckResourceIsEnough</span><span class="p">(</span><span class="nx">pod</span> <span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Pod</span><span class="p">,</span> <span class="nx">nodes</span> <span class="p">[]</span><span class="o">*</span><span class="nx">v1</span><span class="p">.</span><span class="nx">Node</span><span class="p">)</span> <span class="p">(</span><span class="kt">bool</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
	<span class="k">return</span> <span class="kc">false</span><span class="p">,</span> <span class="kc">nil</span>
<span class="p">}</span></pre></td></tr></table>
</div>
</div>
<p>scheduler/core/generic_scheduler.go</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//fanux add checkBatchPodResource
	flag, err := util.CheckResourceIsEnough(pod, filteredNodes)
	if !flag || err != nil {
		return &#34;&#34;, err
	}

	trace.Step(&#34;Prioritizing&#34;)</pre></td></tr></table>
</div>
</div>
<p>处理资源不足时的情况</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></pre></td>
<td class="lntd">
<pre class="chroma">	suggestedHost, err := sched.schedule(pod)

	//fanux add handle if resource not enough
	if strings.Contains(err.Error(), common.BatchResourceNotEnough) {
		sched.Config.BatchScheduler.HandleResourceNotEnough(pod)
	} else if err != nil {</pre></td></tr></table>
</div>
</div>
<h2 id="如何获取节点已经分配gpu的数量">如何获取节点已经分配GPU的数量</h2>

<p>nodeInfo allocatableResource - requestedResource is avaliavle resource</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></pre></td>
<td class="lntd">
<pre class="chroma">	requestedResource *Resource
	nonzeroRequest    *Resource
	allocatableResource *Resource</pre></td></tr></table>
</div>
</div>
<p>GPU 是 ScalarResources, 资源名称叫 : <code>NVIDIAGPUResourceName = &quot;nvidia.com/gpu&quot;</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></pre></td>
<td class="lntd">
<pre class="chroma">type Resource struct {
	MilliCPU         int64
	Memory           int64
	EphemeralStorage int64
	// We store allowedPodNumber (which is Node.Status.Allocatable.Pods().Value())
	// explicitly as int, to avoid conversions and improve performance.
	AllowedPodNumber int
	// ScalarResources
	ScalarResources map[v1.ResourceName]int64
}</pre></td></tr></table>
</div>
</div>
<h2 id="增加podupdater-可更新podcondition状态">增加podupdater，可更新podcondition状态</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span></pre></td>
<td class="lntd">
<pre class="chroma">	batchScheduler := batch.NewBatchScheduler(c.schedulerCache, c.podQueue, &amp;binder{c.client}, &amp;podConditionUpdater{c.client})</pre></td></tr></table>
</div>
</div>
<h2 id="需要把batch-scheduler的cache给generic-scheduler资源检查时需要用">需要把batch scheduler的cache给generic_scheduler资源检查时需要用</h2>

<p>需要知道已经有哪些pod已经assume过了，把这个数量减掉才是batch任务还需要多少GPU</p>

<p>core/generic_scheduler.go</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//fanux add batch Cache
	//check batch pod resource is enough need batch scheduler cache
	BatchCache common.TaskCache</pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//fanux add checkBatchPodResource
	flag, err := common.CheckResourceIsEnough(pod, filteredNodes, g.cachedNodeInfoMap, g.BatchCache)</pre></td></tr></table>
</div>
</div>
<p>factory.go</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//fanux check batch resource is enough need batch scheduler cache
	batchCache := batchScheduler.GetTaskCache()

	algo := core.NewGenericScheduler(
        ...
		batchCache,
	)</pre></td></tr></table>
</div>
</div>
<p>then checkresource :</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></pre></td>
<td class="lntd">
<pre class="chroma">	//shoud not use metadata, need use metadata - assumed pod num in batch cache
	_, podNum := GetPodBathMeta(pod)
	podNum -= batchCache.GetTaskAssumedPodNum(pod)</pre></td></tr></table>
</div>
</div>
<h2 id="检查资源是否充足详细算法">检查资源是否充足详细算法：</h2>

<p>有很多细节</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span></pre></td>
<td class="lntd">
<pre class="chroma">//获取pod需要多少GPU，这个需要把pod里容器配额加起来
func GetPodGPUCount(pod *v1.Pod) (count int) {
	for _, c := range pod.Spec.Containers {
		limit, ok := c.Resources.Limits[NVIDIAGPUResourceName]
		l, okay := limit.AsInt64()
		if !ok || !okay {
			continue
		}
		count += int(l)
	}

	glog.Infof(&#34;Pod [%s] need GPU [%d]&#34;, pod.GetName(), count)

	return
}

//获取节点空闲GPU，需要把可分配的减去已经申请的
func GetNodeFreeGPU(nodeInfo *cache.NodeInfo) int {
	if nodeInfo == nil {
		return 0
	}

	allocatable, ok := nodeInfo.AllocatableResource().ScalarResources[NVIDIAGPUResourceName]
	if !ok {
		glog.Errorf(&#34;can&#39;t fetch allocatable GPU : %v&#34;, nodeInfo)
		return 0
	}
	glog.Infof(&#34;node [%s] allocatable GPU [%d]&#34;, nodeInfo.Node().Name, allocatable)

	requested, ok := nodeInfo.RequestedResource().ScalarResources[NVIDIAGPUResourceName]
	if !ok {
		//glog.Errorf(&#34;can&#39;t fetch requested GPU : %v&#34;, nodeInfo)
		//return 0
		requested = 0
	}
	glog.Infof(&#34;node [%s] requested GPU [%d]&#34;, nodeInfo.Node().Name, requested)

	available := allocatable - requested

	glog.Infof(&#34;available node [%s] GPU : [%d]&#34;, nodeInfo.Node().Name, available)

	return int(available)
}

//这里最关键的点是需要把annotations里面获取的task pod总数减去已经assume过的batch pod，这样才是真实所需
func CheckResourceIsEnough(pod *v1.Pod, nodes []*v1.Node, cachedNodeInfoMap map[string]*cache.NodeInfo, batchCache TaskCache) (bool, error) {
	//if is not batch pod, return true,nil
	if !IsBatch(pod) {
		glog.Infof(&#34;pod %s is not batch pod&#34;, pod.GetName())
		return true, nil
	}

	//shoud not use metadata, need use metadata - ready pod num in batch cache
	_, podNum := GetPodBathMeta(pod)
	podNum -= batchCache.GetTaskAssumedPodNum(pod)

	everyPodNeedsGPU := GetPodGPUCount(pod)
	if everyPodNeedsGPU == 0 {
		glog.Infof(&#34;pod %s require 0 GPU&#34;, pod.GetName())
		return true, nil
	}

	// TODO maybe check nodes[1:], node[0] already allocate a pod, CPU and other metric may reach limit
	for _, node := range nodes {
		nodeInfo, ok := cachedNodeInfoMap[node.Name]
		if !ok {
			continue
		}
		nodeFree := GetNodeFreeGPU(nodeInfo)
		podNum -= nodeFree / everyPodNeedsGPU
		glog.Infof(&#34;pod: [%s] node: [%s] podNum [%d] nodeFree [%d] podNeed [%d]&#34;, pod.GetName(), node.Name, podNum, nodeFree, everyPodNeedsGPU)
		if podNum &lt;= 0 {
			return true, nil
		}
	}

	return false, fmt.Errorf(&#34;BatchResourceNotEnough : pod name is %s&#34;, pod.GetName())
}

//判断是不是batch pod
func IsBatch(pod *v1.Pod) bool {
	g, n := GetPodBathMeta(pod)
	if g == &#34;&#34; || n == 0 {
		glog.Infof(&#34;The pod&#39;s group name is empty string,pod name is %v.&#34;, pod.GetName())
		return false
	}
	return true
}</pre></td></tr></table>
</div>
</div>
<h1 id="关于gpu的使用与发现">关于GPU的使用与发现</h1>

<p><a href="https://github.com/sealyun/GPU/releases">资源包</a></p>

<p>这里包含docker nv-docker GPU-device plugin
install.sh&hellip;</p>

<p>/etc/docker/daemon.json</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></pre></td>
<td class="lntd">
<pre class="chroma">[root@compute-gpu006 ~]# cat /etc/docker/daemon.json
{
    &#34;default-runtime&#34;:&#34;nvidia&#34;,
    &#34;runtimes&#34;: {
        &#34;nvidia&#34;: {
            &#34;path&#34;: &#34;/usr/bin/nvidia-container-runtime&#34;,
            &#34;runtimeArgs&#34;: []
        }
    }
}</pre></td></tr></table>
</div>
</div>
<p>kubectl describe node xxx:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></pre></td>
<td class="lntd">
<pre class="chroma">Capacity:
 cpu:                72
 ephemeral-storage:  222779Mi
 hugepages-1Gi:      0
 hugepages-2Mi:      2Gi
 memory:             791014684Ki
 nvidia.com/gpu:     2                # 这里就能看到GPU了
 pods:               110
Allocatable:
 cpu:                72
 ephemeral-storage:  210240641086
 hugepages-1Gi:      0
 hugepages-2Mi:      2Gi
 memory:             788815132Ki
 nvidia.com/gpu:     2
 pods:               110</pre></td></tr></table>
</div>
</div>
<h1 id="总结">总结</h1>

<p>原生调度器的设计就是pod one by one，所以做这个功能的开发还是改动非常大的，也是比较困难的，工作量不大，但是需要找到一个优雅的方案，
合理的架构比较麻烦,想了很久做了这个侵入不太大的实现方案，欢迎大家一起讨论</p>

<h1 id="公众号">公众号：</h1>

<p><img src="https://sealyun.com/kubernetes-qrcode.jpg" alt="sealyun" /></p>

<h3 id="微信群">微信群：</h3>

<p><img src="/wechatgroup1.png" alt="" /></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">fanux</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2018-12-25
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/event/">event</a>
          <a href="/tags/dotscale/">dotScale</a>
          <a href="/tags/sketchnote/">sketchnote</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/prometheus-operator-envoy/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">使用prometheus operator监控envoy</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/docs/">
            <span class="next-text nav-default">sealyun kubernetes离线包文档</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="comments-gitment"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitment@0.0.3/style/default.min.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/gitment@0.0.3/dist/gitment.browser.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitment = new Gitment({
        id: '2018-12-25 10:54:24 \x2b0200 \x2b0200',
        title: 'kube-scheduler定制，支持深度学习批处理任务调度',
        link: decodeURI(location.href),
        desc: 'kubernetes集群三步安装 什么是批处理任务 深度学习中经常会出现多机多卡的任务，也就是同事会起多个pod，但是这多个pod属于同一个任务',
        owner: 'fanux',
        repo: 'fanux.github.io',
        oauth: {
          client_id: 'dbec2d3194e8cd765fae',
          client_secret: 'a628bdc03410089c6b6460250a8756a9189a6f4c'
        }
      });
      gitment.render('comments-gitment');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-facebook" title="facebook"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-google" title="google"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" class="iconfont icon-instagram" title="instagram"></a>
      <a href="http://localhost:1313" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://sealyun.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">fanux</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
