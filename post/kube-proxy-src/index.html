<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>kube-proxy源码解析 - sealyun | kubernetes安装</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?2803648cc5852dd3e9e46bbd0bf63366";
          var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
            })();
        </script>


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119962244-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119962244-1');
</script>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="fanux" />
  <meta name="description" content="广告 | kubernetes离线安装包，仅需三步 kube-proxy源码解析 ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.40.3" />


<link rel="canonical" href="https://sealyun.com/post/kube-proxy-src/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="kube-proxy源码解析" />
<meta property="og:description" content="广告 | kubernetes离线安装包，仅需三步 kube-proxy源码解析 ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sealyun.com/post/kube-proxy-src/" />



<meta property="article:published_time" content="2018-06-20T10:54:24&#43;02:00"/>

<meta property="article:modified_time" content="2018-06-20T10:54:24&#43;02:00"/>











<meta itemprop="name" content="kube-proxy源码解析">
<meta itemprop="description" content="广告 | kubernetes离线安装包，仅需三步 kube-proxy源码解析 ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以">


<meta itemprop="datePublished" content="2018-06-20T10:54:24&#43;02:00" />
<meta itemprop="dateModified" content="2018-06-20T10:54:24&#43;02:00" />
<meta itemprop="wordCount" content="3674">



<meta itemprop="keywords" content="event,dotScale,sketchnote," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="kube-proxy源码解析"/>
<meta name="twitter:description" content="广告 | kubernetes离线安装包，仅需三步 kube-proxy源码解析 ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SealYun</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/pro/istio">
        <li class="mobile-menu-item">Istio下载</li>
      </a><a href="/pro/products">
        <li class="mobile-menu-item">Kubernetes下载</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SealYun</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/pro/istio">Istio下载</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/pro/products">Kubernetes下载</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">kube-proxy源码解析</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-06-20 </span>
        
        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li><a href="#kube-proxy源码解析">kube-proxy源码解析</a>
<ul>
<li><a href="#初始化配置">初始化配置</a></li>
<li><a href="#启动proxyserver">启动proxyServer</a></li>
<li><a href="#开始监听">开始监听</a></li>
<li><a href="#proxier-实现">Proxier 实现</a></li>
<li><a href="#syncproxyrules">syncProxyRules</a></li>
<li><a href="#创建service实现">创建service实现</a></li>
<li><a href="#总结">总结</a></li>
</ul></li>
<li><a href="#公众号">公众号：</a>
<ul>
<li>
<ul>
<li><a href="#微信群">微信群：</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      

<blockquote>
<p>广告 | <a href="http://sealyun.com/pro/products/">kubernetes离线安装包，仅需三步</a></p>
</blockquote>

<h1 id="kube-proxy源码解析">kube-proxy源码解析</h1>

<p>ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以此模式的源码解析为主，如果想去了解iptables模式的原理，可以去参考其实现，架构上无差别。</p>

<p>kube-proxy主要功能是监听service和endpoint的事件，然后下放代理策略到机器上。 底层调用<a href="https://github.com/docker/libnetwork">docker/libnetwork</a>, 而libnetwork最终调用了<a href="https://github.com/vishvananda/netlink">netlink</a> 与netns来实现ipvs的创建等动作</p>

<h2 id="初始化配置">初始化配置</h2>

<p>代码入口：<code>cmd/kube-proxy/app/server.go</code> Run() 函数</p>

<p>通过命令行参数去初始化proxyServer的配置</p>

<pre><code>proxyServer, err := NewProxyServer(o)
</code></pre>

<pre><code>type ProxyServer struct {
    // k8s client
	Client                 clientset.Interface
	EventClient            v1core.EventsGetter

    // ipvs 相关接口
	IptInterface           utiliptables.Interface
	IpvsInterface          utilipvs.Interface
	IpsetInterface         utilipset.Interface

    // 处理同步时的处理器
	Proxier                proxy.ProxyProvider

    // 代理模式，ipvs iptables userspace kernelspace(windows)四种
	ProxyMode              string
    // 配置同步周期
	ConfigSyncPeriod       time.Duration

    // service 与 endpoint 事件处理器
	ServiceEventHandler    config.ServiceHandler
	EndpointsEventHandler  config.EndpointsHandler
}
</code></pre>

<p>Proxier是主要入口，抽象了两个函数：</p>

<pre><code>type ProxyProvider interface {
	// Sync immediately synchronizes the ProxyProvider's current state to iptables.
	Sync()
	// 定期执行
	SyncLoop()
}
</code></pre>

<p>ipvs 的interface 这个很重要：</p>

<pre><code>type Interface interface {
	// 删除所有规则
	Flush() error
	// 增加一个virtual server
	AddVirtualServer(*VirtualServer) error

	UpdateVirtualServer(*VirtualServer) error
	DeleteVirtualServer(*VirtualServer) error
	GetVirtualServer(*VirtualServer) (*VirtualServer, error)
	GetVirtualServers() ([]*VirtualServer, error)

    // 给virtual server加个realserver, 如 VirtualServer就是一个clusterip realServer就是pod(或者自定义的endpoint)
	AddRealServer(*VirtualServer, *RealServer) error
	GetRealServers(*VirtualServer) ([]*RealServer, error)
	DeleteRealServer(*VirtualServer, *RealServer) error
}
</code></pre>

<p>我们在下文再详细看ipvs_linux是如何实现上面接口的</p>

<p>virtual server与realserver, 最重要的是ip:port，然后就是一些代理的模式如sessionAffinity等:</p>

<pre><code>type VirtualServer struct {
	Address   net.IP
	Protocol  string
	Port      uint16
	Scheduler string
	Flags     ServiceFlags
	Timeout   uint32
}

type RealServer struct {
	Address net.IP
	Port    uint16
	Weight  int
}
</code></pre>

<blockquote>
<p>创建apiserver client</p>
</blockquote>

<pre><code>client, eventClient, err := createClients(config.ClientConnection, master)
</code></pre>

<blockquote>
<p>创建Proxier 这是仅仅关注ipvs模式的proxier</p>
</blockquote>

<pre><code>else if proxyMode == proxyModeIPVS {
		glog.V(0).Info(&quot;Using ipvs Proxier.&quot;)
		proxierIPVS, err := ipvs.NewProxier(
			iptInterface,
			ipvsInterface,
			ipsetInterface,
			utilsysctl.New(),
			execer,
			config.IPVS.SyncPeriod.Duration,
			config.IPVS.MinSyncPeriod.Duration,
			config.IPTables.MasqueradeAll,
			int(*config.IPTables.MasqueradeBit),
			config.ClusterCIDR,
			hostname,
			getNodeIP(client, hostname),
			recorder,
			healthzServer,
			config.IPVS.Scheduler,
		)
...
		proxier = proxierIPVS
		serviceEventHandler = proxierIPVS
		endpointsEventHandler = proxierIPVS
</code></pre>

<p>这个Proxier具备以下方法：</p>

<pre><code>   +OnEndpointsAdd(endpoints *api.Endpoints)
   +OnEndpointsDelete(endpoints *api.Endpoints)
   +OnEndpointsSynced()
   +OnEndpointsUpdate(oldEndpoints, endpoints *api.Endpoints)
   +OnServiceAdd(service *api.Service)
   +OnServiceDelete(service *api.Service)
   +OnServiceSynced()
   +OnServiceUpdate(oldService, service *api.Service)
   +Sync()
   +SyncLoop()
</code></pre>

<p>所以ipvs的这个Proxier实现了我们需要的绝大部分接口</p>

<p>小结一下：</p>

<pre><code>     +-----------&gt; endpointHandler
     |
     +-----------&gt; serviceHandler
     |                ^
     |                | +-------------&gt; sync 定期同步等
     |                | |
ProxyServer---------&gt; Proxier --------&gt; service 事件回调           
     |                  |                                                
     |                  +-------------&gt; endpoint事件回调          
     |                                             |  触发
     +-----&gt; ipvs interface ipvs handler     &lt;-----+
</code></pre>

<h2 id="启动proxyserver">启动proxyServer</h2>

<ol>
<li>检查是不是带了clean up参数，如果带了那么清除所有规则退出</li>
<li>OOM adjuster貌似没实现，忽略</li>
<li>resouceContainer也没实现，忽略</li>
<li>启动metrics服务器，这个挺重要，比如我们想监控时可以传入这个参数, 包含promethus的 metrics. metrics-bind-address参数</li>
<li>启动informer, 开始监听事件，分别启动协程处理。</li>
</ol>

<p>1 2 3 4我们都不用太关注，细看5即可：</p>

<pre><code>informerFactory := informers.NewSharedInformerFactory(s.Client, s.ConfigSyncPeriod)

serviceConfig := config.NewServiceConfig(informerFactory.Core().InternalVersion().Services(), s.ConfigSyncPeriod)
// 注册 service handler并启动
serviceConfig.RegisterEventHandler(s.ServiceEventHandler)
// 这里面仅仅是把ServiceEventHandler赋值给informer回调 
go serviceConfig.Run(wait.NeverStop)

endpointsConfig := config.NewEndpointsConfig(informerFactory.Core().InternalVersion().Endpoints(), s.ConfigSyncPeriod)
// 注册endpoint 
endpointsConfig.RegisterEventHandler(s.EndpointsEventHandler)
go endpointsConfig.Run(wait.NeverStop)

go informerFactory.Start(wait.NeverStop)
</code></pre>

<p>serviceConfig.Run与endpointConfig.Run仅仅是给回调函数赋值, 所以注册的handler就给了informer, informer监听到事件时就会回调：</p>

<pre><code>for i := range c.eventHandlers {
	glog.V(3).Infof(&quot;Calling handler.OnServiceSynced()&quot;)
	c.eventHandlers[i].OnServiceSynced()
}
</code></pre>

<p>那么问题来了，注册进去的这个handler是啥？ 回顾一下上文的</p>

<pre><code>		serviceEventHandler = proxierIPVS
		endpointsEventHandler = proxierIPVS
</code></pre>

<p>所以都是这个proxierIPVS</p>

<p>handler的回调函数, informer会回调这几个函数，所以我们在自己开发时实现这个interface注册进去即可：</p>

<pre><code>type ServiceHandler interface {
	// OnServiceAdd is called whenever creation of new service object
	// is observed.
	OnServiceAdd(service *api.Service)
	// OnServiceUpdate is called whenever modification of an existing
	// service object is observed.
	OnServiceUpdate(oldService, service *api.Service)
	// OnServiceDelete is called whenever deletion of an existing service
	// object is observed.
	OnServiceDelete(service *api.Service)
	// OnServiceSynced is called once all the initial even handlers were
	// called and the state is fully propagated to local cache.
	OnServiceSynced()
}
</code></pre>

<h2 id="开始监听">开始监听</h2>

<pre><code>go informerFactory.Start(wait.NeverStop)
</code></pre>

<p>这里执行后，我们创建删除service endpoint等动作都会被监听到，然后回调,回顾一下上面的图，最终都是由Proxier去实现，所以后面我们重点关注Proxier即可</p>

<pre><code>s.Proxier.SyncLoop()
</code></pre>

<p>然后开始SyncLoop,下文开讲</p>

<h2 id="proxier-实现">Proxier 实现</h2>

<p>我们创建一个service时OnServiceAdd方法会被调用, 这里记录一下之前的状态与当前状态两个东西，然后发个信号给syncRunner让它去处理：</p>

<pre><code>func (proxier *Proxier) OnServiceAdd(service *api.Service) {
	namespacedName := types.NamespacedName{Namespace: service.Namespace, Name: service.Name}
	if proxier.serviceChanges.update(&amp;namespacedName, nil, service) &amp;&amp; proxier.isInitialized() {
		proxier.syncRunner.Run()
	}
}
</code></pre>

<p>记录service 信息,可以看到没做什么事，就是把service存在map里, 如果没变直接删掉map信息不做任何处理：</p>

<pre><code>change, exists := scm.items[*namespacedName]
if !exists {
	change = &amp;serviceChange{}
    // 老的service信息
	change.previous = serviceToServiceMap(previous)
	scm.items[*namespacedName] = change
}
// 当前监听到的service信息
change.current = serviceToServiceMap(current)

如果一样，直接删除
if reflect.DeepEqual(change.previous, change.current) {
	delete(scm.items, *namespacedName)
}
</code></pre>

<p>proxier.syncRunner.Run() 里面就发送了一个信号</p>

<pre><code>select {
case bfr.run &lt;- struct{}{}:
default:
}
</code></pre>

<p>这里面处理了这个信号</p>

<pre><code>s.Proxier.SyncLoop()

func (proxier *Proxier) SyncLoop() {
	// Update healthz timestamp at beginning in case Sync() never succeeds.
	if proxier.healthzServer != nil {
		proxier.healthzServer.UpdateTimestamp()
	}
	proxier.syncRunner.Loop(wait.NeverStop)
}
</code></pre>

<p>runner里收到信号执行，没收到信号会定期执行：</p>

<pre><code>func (bfr *BoundedFrequencyRunner) Loop(stop &lt;-chan struct{}) {
	glog.V(3).Infof(&quot;%s Loop running&quot;, bfr.name)
	bfr.timer.Reset(bfr.maxInterval)
	for {
		select {
		case &lt;-stop:
			bfr.stop()
			glog.V(3).Infof(&quot;%s Loop stopping&quot;, bfr.name)
			return
		case &lt;-bfr.timer.C():  // 定期执行
			bfr.tryRun()
		case &lt;-bfr.run:
			bfr.tryRun()       // 收到事件信号执行
		}
	}
}
</code></pre>

<p>这个bfr runner里我们最需要主意的是一个回调函数，tryRun里检查这个回调是否满足被调度的条件：</p>

<pre><code>type BoundedFrequencyRunner struct {
	name        string        // the name of this instance
	minInterval time.Duration // the min time between runs, modulo bursts
	maxInterval time.Duration // the max time between runs

	run chan struct{} // try an async run

	mu      sync.Mutex  // guards runs of fn and all mutations
	fn      func()      // function to run, 这个回调
	lastRun time.Time   // time of last run
	timer   timer       // timer for deferred runs
	limiter rateLimiter // rate limiter for on-demand runs
}

// 传入的proxier.syncProxyRules这个函数
proxier.syncRunner = async.NewBoundedFrequencyRunner(&quot;sync-runner&quot;, proxier.syncProxyRules, minSyncPeriod, syncPeriod, burstSyncs)
</code></pre>

<p>这是个600行左右的搓逼函数，也是处理主要逻辑的地方。</p>

<h2 id="syncproxyrules">syncProxyRules</h2>

<ol>
<li>设置一些iptables规则，如mark与comment</li>
<li>确定机器上有网卡，ipvs需要绑定地址到上面</li>
<li>确定有ipset，ipset是iptables的扩展，可以给一批地址设置iptables规则
&hellip;(又臭又长，重复代码多，看不下去了，细节问题自己去看吧)</li>
<li>我们最关注的，如何去处理VirtualServer的</li>
</ol>

<pre><code>serv := &amp;utilipvs.VirtualServer{
	Address:   net.ParseIP(ingress.IP),
	Port:      uint16(svcInfo.port),
	Protocol:  string(svcInfo.protocol),
	Scheduler: proxier.ipvsScheduler,
}
if err := proxier.syncService(svcNameString, serv, false); err == nil {
	if err := proxier.syncEndpoint(svcName, svcInfo.onlyNodeLocalEndpoints, serv); err != nil {
	}
}
</code></pre>

<p>看下实现, 如果没有就创建，如果已存在就更新, 给网卡绑定service的cluster ip：</p>

<pre><code>func (proxier *Proxier) syncService(svcName string, vs *utilipvs.VirtualServer, bindAddr bool) error {
	appliedVirtualServer, _ := proxier.ipvs.GetVirtualServer(vs)
	if appliedVirtualServer == nil || !appliedVirtualServer.Equal(vs) {
		if appliedVirtualServer == nil {
			if err := proxier.ipvs.AddVirtualServer(vs); err != nil {
				return err
			}
		} else {
			if err := proxier.ipvs.UpdateVirtualServer(appliedVirtualServer); err != nil {
				return err
			}
		}
	}

	// bind service address to dummy interface even if service not changed,
	// in case that service IP was removed by other processes
	if bindAddr {
		_, err := proxier.netlinkHandle.EnsureAddressBind(vs.Address.String(), DefaultDummyDevice)
		if err != nil {
			return err
		}
	}
	return nil
}
</code></pre>

<h2 id="创建service实现">创建service实现</h2>

<p>现在可以去看ipvs的AddVirtualServer的实现了，主要是利用socket与内核进程通信做到的。
<code>pkg/util/ipvs/ipvs_linux.go</code> 里 runner结构体实现了这些方法, 这里用到了 docker/libnetwork/ipvs库：</p>

<pre><code>// runner implements Interface.
type runner struct {
	exec       utilexec.Interface
	ipvsHandle *ipvs.Handle
}

// New returns a new Interface which will call ipvs APIs.
func New(exec utilexec.Interface) Interface {
	ihandle, err := ipvs.New(&quot;&quot;) // github.com/docker/libnetwork/ipvs
	if err != nil {
		glog.Errorf(&quot;IPVS interface can't be initialized, error: %v&quot;, err)
		return nil
	}
	return &amp;runner{
		exec:       exec,
		ipvsHandle: ihandle,
	}
}
</code></pre>

<p>New的时候创建了一个特殊的socket, 这里与我们普通的socket编程无差别，关键是syscall.AF_NETLINK这个参数，代表与内核进程通信：</p>

<pre><code>sock, err := nl.GetNetlinkSocketAt(n, netns.None(), syscall.NETLINK_GENERIC)

func getNetlinkSocket(protocol int) (*NetlinkSocket, error) {
	fd, err := syscall.Socket(syscall.AF_NETLINK, syscall.SOCK_RAW|syscall.SOCK_CLOEXEC, protocol)
	if err != nil {
		return nil, err
	}
	s := &amp;NetlinkSocket{
		fd: int32(fd),
	}
	s.lsa.Family = syscall.AF_NETLINK
	if err := syscall.Bind(fd, &amp;s.lsa); err != nil {
		syscall.Close(fd)
		return nil, err
	}

	return s, nil
}
</code></pre>

<p>创建一个service, 转换成docker service格式，直接调用:</p>

<pre><code>// AddVirtualServer is part of Interface.
func (runner *runner) AddVirtualServer(vs *VirtualServer) error {
	eSvc, err := toBackendService(vs)
	if err != nil {
		return err
	}
	return runner.ipvsHandle.NewService(eSvc)
}
</code></pre>

<p>然后就是把service信息打包，往socket里面写即可：</p>

<pre><code>
func (i *Handle) doCmdwithResponse(s *Service, d *Destination, cmd uint8) ([][]byte, error) {
	req := newIPVSRequest(cmd)
	req.Seq = atomic.AddUint32(&amp;i.seq, 1)

	if s == nil {
		req.Flags |= syscall.NLM_F_DUMP                    //Flag to dump all messages
		req.AddData(nl.NewRtAttr(ipvsCmdAttrService, nil)) //Add a dummy attribute
	} else {
		req.AddData(fillService(s))
	} // 把service塞到请求中

	if d == nil {
		if cmd == ipvsCmdGetDest {
			req.Flags |= syscall.NLM_F_DUMP
		}

	} else {
		req.AddData(fillDestinaton(d))
	}

    // 给内核进程发送service信息
	res, err := execute(i.sock, req, 0)
	if err != nil {
		return [][]byte{}, err
	}

	return res, nil
}
</code></pre>

<blockquote>
<p>构造请求</p>
</blockquote>

<pre><code>func newIPVSRequest(cmd uint8) *nl.NetlinkRequest {
	return newGenlRequest(ipvsFamily, cmd)
}
</code></pre>

<p>在构造请求时传入的是ipvs协议簇</p>

<p>然后构造一个与内核通信的消息头</p>

<pre><code>func NewNetlinkRequest(proto, flags int) *NetlinkRequest {
	return &amp;NetlinkRequest{
		NlMsghdr: syscall.NlMsghdr{
			Len:   uint32(syscall.SizeofNlMsghdr),
			Type:  uint16(proto),
			Flags: syscall.NLM_F_REQUEST | uint16(flags),
			Seq:   atomic.AddUint32(&amp;nextSeqNr, 1),
		},
	}
}
</code></pre>

<blockquote>
<p>给消息加Data,这个Data是个数组，需要实现两个方法：</p>
</blockquote>

<pre><code>type NetlinkRequestData interface {
	Len() int  // 长度
	Serialize() []byte // 序列化, 内核通信也需要一定的数据格式，service信息也需要实现
}
</code></pre>

<p>比如 header是这样序列化的, 一看愣住了，思考好久才看懂：
拆下看：
(*[unsafe.Sizeof(<em>hdr)]byte) 一个</em>[]byte类型，长度就是结构体大小
(unsafe.Pointer(hdr))把结构体转成byte指针类型
加个*取它的值
用[:]转成byte返回</p>

<pre><code>func (hdr *genlMsgHdr) Serialize() []byte {
	return (*(*[unsafe.Sizeof(*hdr)]byte)(unsafe.Pointer(hdr)))[:]
}
</code></pre>

<blockquote>
<p>发送service信息给内核</p>
</blockquote>

<p>一个很普通的socket发送接收数据</p>

<pre><code>func execute(s *nl.NetlinkSocket, req *nl.NetlinkRequest, resType uint16) ([][]byte, error) {
	var (
		err error
	)

	if err := s.Send(req); err != nil {
		return nil, err
	}

	pid, err := s.GetPid()
	if err != nil {
		return nil, err
	}

	var res [][]byte

done:
	for {
		msgs, err := s.Receive()
		if err != nil {
			return nil, err
		}
		for _, m := range msgs {
			if m.Header.Seq != req.Seq {
				continue
			}
			if m.Header.Pid != pid {
				return nil, fmt.Errorf(&quot;Wrong pid %d, expected %d&quot;, m.Header.Pid, pid)
			}
			if m.Header.Type == syscall.NLMSG_DONE {
				break done
			}
			if m.Header.Type == syscall.NLMSG_ERROR {
				error := int32(native.Uint32(m.Data[0:4]))
				if error == 0 {
					break done
				}
				return nil, syscall.Errno(-error)
			}
			if resType != 0 &amp;&amp; m.Header.Type != resType {
				continue
			}
			res = append(res, m.Data)
			if m.Header.Flags&amp;syscall.NLM_F_MULTI == 0 {
				break done
			}
		}
	}
	return res, nil
}
</code></pre>

<blockquote>
<p>Service 数据打包
这里比较细，核心思想就是内核只认一定格式的标准数据，我们把service信息按其标准打包发送给内核即可。
至于怎么打包的就不详细讲了。</p>

<pre><code>func fillService(s *Service) nl.NetlinkRequestData {
	cmdAttr := nl.NewRtAttr(ipvsCmdAttrService, nil)
	nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrAddressFamily, nl.Uint16Attr(s.AddressFamily))
	if s.FWMark != 0 {
		nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrFWMark, nl.Uint32Attr(s.FWMark))
	} else {
		nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrProtocol, nl.Uint16Attr(s.Protocol))
		nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrAddress, rawIPData(s.Address))

		// Port needs to be in network byte order.
		portBuf := new(bytes.Buffer)
		binary.Write(portBuf, binary.BigEndian, s.Port)
		nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrPort, portBuf.Bytes())
	}

	nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrSchedName, nl.ZeroTerminated(s.SchedName))
	if s.PEName != &quot;&quot; {
		nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrPEName, nl.ZeroTerminated(s.PEName))
	}
	f := &amp;ipvsFlags{
		flags: s.Flags,
		mask:  0xFFFFFFFF,
	}
	nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrFlags, f.Serialize())
	nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrTimeout, nl.Uint32Attr(s.Timeout))
	nl.NewRtAttrChild(cmdAttr, ipvsSvcAttrNetmask, nl.Uint32Attr(s.Netmask))
	return cmdAttr
}
</code></pre>
</blockquote>

<h2 id="总结">总结</h2>

<p>Service总体来讲代码比较简单，但是觉得有些地方实现的有点绕，不够简单直接。 总体来说就是监听apiserver事件，然后比对 处理，定期也会去执行同步策略.</p>

<h1 id="公众号">公众号：</h1>

<p><img src="https://sealyun.com/kubernetes-qrcode.jpg" alt="sealyun" /></p>

<h3 id="微信群">微信群：</h3>

<p><img src="/wechatgroup1.png" alt="" /></p>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">fanux</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">2018-06-20</span>
  </p>
  
  
</div>

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/event/">event</a>
          
          <a href="/tags/dotscale/">dotScale</a>
          
          <a href="/tags/sketchnote/">sketchnote</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/kube-dev/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">kubernetes开发指南</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        
          <a class="next" href="/post/k8s-ipvs/">
            <span class="next-text nav-default">kubernetes启用ipvs</span>
            <span class="prev-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  <div id="comments-gitment"></div>
  <link rel="stylesheet" href="/lib/gitment/gitment-0.0.3.min.css">
    <script src="/lib/gitment/gitment-0.0.3.min.js"></script>
  <script type="text/javascript">
  const gitment = new Gitment({
    id: '2018-06-20 10:54:24 \x2b0200 \x2b0200',
    title: 'kube-proxy源码解析',
    link: decodeURI(location.href),
    desc: '广告 | kubernetes离线安装包，仅需三步 kube-proxy源码解析 ipvs相对于iptables模式具备较高的性能与稳定性, 本文讲以',
    owner: 'fanux',
    repo: 'fanux.github.io',
    oauth: {
      client_id: 'dbec2d3194e8cd765fae',
      client_secret: 'a628bdc03410089c6b6460250a8756a9189a6f4c'
    }
  })
  gitment.render('comments-gitment')
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:fhtjob@hotmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/fanux/" class="iconfont icon-github" title="github"></a>
  <a href="https://sealyun.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    
      2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">fanux</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>








</body>
</html>
